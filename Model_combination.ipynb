{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Instruction**\n",
        "\n",
        "The file is designed to generate predictions by combining the outputs of multiple models. To run the code, you need:\n",
        "\n",
        "1. The predicted probabilities for the test set from both models, in the format: (ID, probability).\n",
        "2. The predicted probabilities for the validation set from both models, along with the true label, in the format: (ID, probability).\n",
        "3. The label of validation set (ID, label).\n",
        "\n",
        "**Note:** This code assumes that the training set is split such that the first 80% is used for training and the last 20% for validation, which matches the team’s current setup.\n",
        "\n",
        "The combination strategies implemented include:\n",
        "\n",
        "1. **Averaging Probabilities:** Directly average the probabilities from the two models and use the result to make final predictions.\n",
        "2. **Rule-Based Combination:** Predict an edge (label = 1) only if both models agree that the probability is above 0.5.\n",
        "3. **Meta-classifier:** Use the probabilities from both models (on the validation set) as input features, train a logistic regression to learn how much to trust each model, and apply the learned weighting to the test set probabilities for final prediction.\n",
        "4. **Confidence-Weighted Averaging:** Weight the predictions of each model based on their validation accuracy, giving more weight to the better-performing model."
      ],
      "metadata": {
        "id": "MxijwBAHabnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "1IkY7ZEPeNbg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisit: upload the necessary data"
      ],
      "metadata": {
        "id": "u0V0m1jwc610"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the probabilities saved from both models\n",
        "gcn_probs = np.load(\"/content/gcn_probs.npy\")\n",
        "rf_probs = np.load(\"/content/rf_probs.npy\")\n",
        "\n",
        "gcn_val_probs = np.load(\"/content/gcn_val_probs.npy\")\n",
        "rf_val_probs = np.load(\"/content/rf_val_probs.npy\")\n",
        "y_val = np.load(\"/content/val_labels.npy\")"
      ],
      "metadata": {
        "id": "mBAY3Ifvc_0u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Averaging Probabilities"
      ],
      "metadata": {
        "id": "L2mOgm-bcTbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both have the same length (sanity check)\n",
        "assert len(gcn_probs) == len(rf_probs), \"Mismatch in prediction lengths!\"\n",
        "\n",
        "# Simple average ensemble\n",
        "final_probs = (gcn_probs + rf_probs) / 2\n",
        "\n",
        "# Convert to binary prediction (threshold at 0.5)\n",
        "final_preds = (final_probs > 0.5).astype(int)\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": np.arange(len(final_preds)),\n",
        "    \"Predicted\": final_preds\n",
        "})\n",
        "\n",
        "# Save final submission\n",
        "submission_file = \"/content/ensemble_submission.csv\"\n",
        "submission.to_csv(submission_file, index=False)\n",
        "print(f\"Ensemble submission saved to {submission_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xK9oDSdcjNH",
        "outputId": "b135d975-1f51-4a8d-c2ad-ff3b729df008"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble submission saved to /content/ensemble_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule-Based Combination"
      ],
      "metadata": {
        "id": "JBXxJm35cZ_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probabilities to binary predictions (threshold = 0.5)\n",
        "gcn_preds = (gcn_probs > 0.5).astype(int)\n",
        "rf_preds = (rf_probs > 0.5).astype(int)\n",
        "\n",
        "# Rule-based ensemble: predict edge only if **both models agree there is an edge**\n",
        "final_preds = (gcn_preds & rf_preds).astype(int)\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": np.arange(len(final_preds)),\n",
        "    \"Predicted\": final_preds\n",
        "})\n",
        "\n",
        "# Save final submission\n",
        "submission_file = \"/content/rule_based_submission.csv\"\n",
        "submission.to_csv(submission_file, index=False)\n",
        "\n",
        "print(f\"Rule-based ensemble submission saved to {submission_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJN5U2MfcmYH",
        "outputId": "c64df1ad-18ce-424a-ef95-10457335f07d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based ensemble submission saved to /content/rule_based_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Meta-classifier"
      ],
      "metadata": {
        "id": "35rkIRzicdt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine into meta features\n",
        "meta_X_train = np.column_stack([gcn_val_probs, rf_val_probs])\n",
        "meta_y_train = y_val\n",
        "\n",
        "# Train meta-classifier\n",
        "meta_clf = LogisticRegression()\n",
        "meta_clf.fit(meta_X_train, meta_y_train)\n",
        "\n",
        "# Evaluate on validation set (just for curiosity)\n",
        "val_preds = meta_clf.predict_proba(meta_X_train)[:, 1]\n",
        "print(f\"Meta-Classifier Validation AUC: {roc_auc_score(meta_y_train, val_preds):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmrBzrP0csqv",
        "outputId": "b5e68f11-6db7-4368-93ba-66b43f61e314"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Classifier Validation AUC: 0.8308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine into meta features for test set\n",
        "meta_X_test = np.column_stack([gcn_probs, rf_probs])\n",
        "\n",
        "# Predict using meta-classifier\n",
        "test_preds = meta_clf.predict(meta_X_test)\n",
        "\n",
        "# Save final submission\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": np.arange(len(test_preds)),\n",
        "    \"Predicted\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"/content/meta_submission.csv\", index=False)\n",
        "print(\"Meta-Classifier predictions saved to /content/meta_submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5XZnEeXcwQs",
        "outputId": "65a107f1-9bda-4b4c-91b6-f36dccc73053"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Classifier predictions saved to /content/meta_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confidence-Weighted Averaging"
      ],
      "metadata": {
        "id": "f5SsAcl6cg9A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJbPepWkaTbO",
        "outputId": "71acf6af-25ad-4aa4-f8db-11887da63f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN Validation AUC: 0.4995\n",
            "RF Validation AUC: 0.8309\n"
          ]
        }
      ],
      "source": [
        "gcn_val_auc = roc_auc_score(y_val, gcn_val_probs)\n",
        "rf_val_auc = roc_auc_score(y_val, rf_val_probs)\n",
        "\n",
        "print(f\"GCN Validation AUC: {gcn_val_auc:.4f}\")\n",
        "print(f\"RF Validation AUC: {rf_val_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = gcn_val_auc / (gcn_val_auc + rf_val_auc)\n",
        "print(f\"GCN Weight (α): {alpha:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmyEBvyNcyvh",
        "outputId": "8764fb91-da64-4b32-b26a-10d1c8f0b7b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN Weight (α): 0.3754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_probs = alpha * gcn_probs + (1 - alpha) * rf_probs"
      ],
      "metadata": {
        "id": "v8GhrUvWc0e6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_preds = (final_probs > 0.5).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": np.arange(len(final_preds)),\n",
        "    \"Predicted\": final_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"/content/confidence_weighted_submission.csv\", index=False)\n",
        "print(\"Confidence-Weighted Averaging submission saved to /content/confidence_weighted_submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5T2DoW4c2RT",
        "outputId": "1b47eec1-3f93-46cc-e26a-932c60a7ee3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence-Weighted Averaging submission saved to /content/confidence_weighted_submission.csv\n"
          ]
        }
      ]
    }
  ]
}