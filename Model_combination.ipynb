{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxijwBAHabnC"
   },
   "source": [
    "# **Instruction**\n",
    "\n",
    "The file is designed to generate predictions by combining the outputs of multiple models. To run the code, you need:\n",
    "\n",
    "1. The predicted probabilities for the test set from both models, in the format: (ID, probability).\n",
    "2. The predicted probabilities for the validation set from both models, along with the true label, in the format: (ID, probability).\n",
    "3. The label of validation set (ID, label).\n",
    "\n",
    "**Note:** This code assumes that the training set is split such that the first 80% is used for training and the last 20% for validation, which matches the team’s current setup.\n",
    "\n",
    "The combination strategies implemented include:\n",
    "\n",
    "1. **Averaging Probabilities:** Directly average the probabilities from the two models and use the result to make final predictions.\n",
    "2. **Rule-Based Combination:** Predict an edge (label = 1) only if both models agree that the probability is above 0.5.\n",
    "3. **Meta-classifier:** Use the probabilities from both models (on the validation set) as input features, train a logistic regression to learn how much to trust each model, and apply the learned weighting to the test set probabilities for final prediction.\n",
    "4. **Confidence-Weighted Averaging:** Weight the predictions of each model based on their validation accuracy, giving more weight to the better-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1IkY7ZEPeNbg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0V0m1jwc610"
   },
   "source": [
    "## Prerequisit: upload the necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mBAY3Ifvc_0u"
   },
   "outputs": [],
   "source": [
    "# Load the probabilities saved from both models\n",
    "gcn_probs = np.load(\"/content/gcn_probs.npy\")\n",
    "rf_probs = np.load(\"/content/rf_probs.npy\")\n",
    "\n",
    "gcn_val_probs = np.load(\"/content/gcn_val_probs.npy\")\n",
    "rf_val_probs = np.load(\"/content/rf_val_probs.npy\")\n",
    "y_val = np.load(\"/content/val_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2mOgm-bcTbt"
   },
   "source": [
    "## Averaging Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xK9oDSdcjNH",
    "outputId": "b135d975-1f51-4a8d-c2ad-ff3b729df008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble submission saved to /content/ensemble_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure both have the same length (sanity check)\n",
    "assert len(gcn_probs) == len(rf_probs), \"Mismatch in prediction lengths!\"\n",
    "\n",
    "# Simple average ensemble\n",
    "final_probs = (gcn_probs + rf_probs) / 2\n",
    "\n",
    "# Convert to binary prediction (threshold at 0.5)\n",
    "final_preds = (final_probs > 0.5).astype(int)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(len(final_preds)),\n",
    "    \"Predicted\": final_preds\n",
    "})\n",
    "\n",
    "# Save final submission\n",
    "submission_file = \"/content/ensemble_submission.csv\"\n",
    "submission.to_csv(submission_file, index=False)\n",
    "print(f\"Ensemble submission saved to {submission_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBXxJm35cZ_S"
   },
   "source": [
    "## Rule-Based Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJN5U2MfcmYH",
    "outputId": "c64df1ad-18ce-424a-ef95-10457335f07d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule-based ensemble submission saved to /content/rule_based_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "gcn_preds = (gcn_probs > 0.5).astype(int)\n",
    "rf_preds = (rf_probs > 0.5).astype(int)\n",
    "\n",
    "# Rule-based ensemble: predict edge only if **both models agree there is an edge**\n",
    "final_preds = (gcn_preds & rf_preds).astype(int)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(len(final_preds)),\n",
    "    \"Predicted\": final_preds\n",
    "})\n",
    "\n",
    "# Save final submission\n",
    "submission_file = \"/content/rule_based_submission.csv\"\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"Rule-based ensemble submission saved to {submission_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35rkIRzicdt-"
   },
   "source": [
    "## Meta-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmrBzrP0csqv",
    "outputId": "b5e68f11-6db7-4368-93ba-66b43f61e314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Classifier Validation AUC: 0.8308\n"
     ]
    }
   ],
   "source": [
    "# Combine into meta features\n",
    "meta_X_train = np.column_stack([gcn_val_probs, rf_val_probs])\n",
    "meta_y_train = y_val\n",
    "\n",
    "# Train meta-classifier\n",
    "meta_clf = LogisticRegression()\n",
    "meta_clf.fit(meta_X_train, meta_y_train)\n",
    "\n",
    "# Evaluate on validation set (just for curiosity)\n",
    "val_preds = meta_clf.predict_proba(meta_X_train)[:, 1]\n",
    "print(f\"Meta-Classifier Validation AUC: {roc_auc_score(meta_y_train, val_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5XZnEeXcwQs",
    "outputId": "65a107f1-9bda-4b4c-91b6-f36dccc73053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Classifier predictions saved to /content/meta_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine into meta features for test set\n",
    "meta_X_test = np.column_stack([gcn_probs, rf_probs])\n",
    "\n",
    "# Predict using meta-classifier\n",
    "test_preds = meta_clf.predict(meta_X_test)\n",
    "\n",
    "# Save final submission\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(len(test_preds)),\n",
    "    \"Predicted\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"/content/meta_submission.csv\", index=False)\n",
    "print(\"Meta-Classifier predictions saved to /content/meta_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5SsAcl6cg9A"
   },
   "source": [
    "## Confidence-Weighted Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJbPepWkaTbO",
    "outputId": "71acf6af-25ad-4aa4-f8db-11887da63f43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Validation AUC: 0.4995\n",
      "RF Validation AUC: 0.8309\n"
     ]
    }
   ],
   "source": [
    "gcn_val_auc = roc_auc_score(y_val, gcn_val_probs)\n",
    "rf_val_auc = roc_auc_score(y_val, rf_val_probs)\n",
    "\n",
    "print(f\"GCN Validation AUC: {gcn_val_auc:.4f}\")\n",
    "print(f\"RF Validation AUC: {rf_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmyEBvyNcyvh",
    "outputId": "8764fb91-da64-4b32-b26a-10d1c8f0b7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Weight (α): 0.3754\n"
     ]
    }
   ],
   "source": [
    "alpha = gcn_val_auc / (gcn_val_auc + rf_val_auc)\n",
    "print(f\"GCN Weight (α): {alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v8GhrUvWc0e6"
   },
   "outputs": [],
   "source": [
    "final_probs = alpha * gcn_probs + (1 - alpha) * rf_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5T2DoW4c2RT",
    "outputId": "1b47eec1-3f93-46cc-e26a-932c60a7ee3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence-Weighted Averaging submission saved to /content/confidence_weighted_submission.csv\n"
     ]
    }
   ],
   "source": [
    "final_preds = (final_probs > 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(len(final_preds)),\n",
    "    \"Predicted\": final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"/content/confidence_weighted_submission.csv\", index=False)\n",
    "print(\"Confidence-Weighted Averaging submission saved to /content/confidence_weighted_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
